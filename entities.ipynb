{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our chat-bot entities file\n",
    "import json\n",
    "with open('entities.json') as json_data:\n",
    "    entities = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [] #Design the Vocabulary (unique words)\n",
    "classes = []\n",
    "documents = []\n",
    "# loop through each sentence in our intents patterns\n",
    "for entity in entities['entities']:\n",
    "    for example in entity['examples']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(example)\n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        # add to documents in our corpus\n",
    "        documents.append((w, entity['tag']))\n",
    "        # add to our classes list\n",
    "        if entity['tag'] not in classes:\n",
    "            classes.append(entity['tag']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem and lower each word and remove duplicates\n",
    "stemmer = LancasterStemmer()\n",
    "words = [stemmer.stem(w.lower()) for w in words ]\n",
    "words = sorted(list(set(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['connect', 'cor', 'devop', 'easyrun', 'par', 'tal', 'tun']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 documents\n",
      "2 classes ['accretio-groups', 'location']\n",
      "7 unique stemmed words ['connect', 'cor', 'devop', 'easyrun', 'par', 'tal', 'tun']\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "print (len(classes), \"classes\", classes)\n",
    "print (len(words), \"unique stemmed words\", words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "output = []\n",
    "\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the examples \n",
    "    example_words = doc[0] \n",
    "    # stem each word\n",
    "    example_words = [stemmer.stem(word.lower()) for word in example_words]\n",
    "    # create our bag of words array\n",
    "    # mark the presence of words as a boolean value, 0 for absent, 1 for present.\n",
    "    for w in words:\n",
    "        bag.append(1) if w in example_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# create train and test lists\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/helmi/.local/lib/python3.5/site-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "---------------------------------\n",
      "Run id: XFKSM1\n",
      "Log directory: tflearn_entities_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 7\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.093s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 7/7\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.62383\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 002 | loss: 0.62383 - acc: 0.3857 -- iter: 7/7\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.68015\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 003 | loss: 0.68015 - acc: 0.6545 -- iter: 7/7\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.69093\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 004 | loss: 0.69093 - acc: 0.6994 -- iter: 7/7\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.69111\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 005 | loss: 0.69111 - acc: 0.7097 -- iter: 7/7\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.69087\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 006 | loss: 0.69087 - acc: 0.7126 -- iter: 7/7\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.69087\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 007 | loss: 0.69087 - acc: 0.7136 -- iter: 7/7\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.69049\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 008 | loss: 0.69049 - acc: 0.7140 -- iter: 7/7\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.69006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 009 | loss: 0.69006 - acc: 0.7142 -- iter: 7/7\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.68960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 010 | loss: 0.68960 - acc: 0.7142 -- iter: 7/7\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.68912\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 011 | loss: 0.68912 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.68863\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 012 | loss: 0.68863 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.68813\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 013 | loss: 0.68813 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.68761\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 014 | loss: 0.68761 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.68708\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 015 | loss: 0.68708 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.68653\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 016 | loss: 0.68653 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.68597\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 017 | loss: 0.68597 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.68540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 018 | loss: 0.68540 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.68480\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 019 | loss: 0.68480 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.68419\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 020 | loss: 0.68419 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.68357\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 021 | loss: 0.68357 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.68225\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 022 | loss: 0.68225 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.68156\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 023 | loss: 0.68156 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.68156\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 024 | loss: 0.68156 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.68011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 025 | loss: 0.68011 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.67935\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 026 | loss: 0.67935 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.67935\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 027 | loss: 0.67935 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.67856\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 028 | loss: 0.67856 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.67774\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 029 | loss: 0.67774 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.67690\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 030 | loss: 0.67690 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.67602\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 031 | loss: 0.67602 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.67511\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 032 | loss: 0.67511 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.67417\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 033 | loss: 0.67417 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.67320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 034 | loss: 0.67320 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.67219\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 035 | loss: 0.67219 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.67006\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 036 | loss: 0.67006 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.67006\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 037 | loss: 0.67006 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.66893\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 038 | loss: 0.66893 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.66777\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 039 | loss: 0.66777 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.66656\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 040 | loss: 0.66656 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.66531\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 041 | loss: 0.66531 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.66401\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 042 | loss: 0.66401 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.66267\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 043 | loss: 0.66267 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.66127\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 044 | loss: 0.66127 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.65983\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 045 | loss: 0.65983 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.65834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 046 | loss: 0.65834 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.65680\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 047 | loss: 0.65680 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.65775\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 048 | loss: 0.65775 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.65572\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 049 | loss: 0.65572 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.65372\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 050 | loss: 0.65372 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.65172\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 051 | loss: 0.65172 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.64973\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 052 | loss: 0.64973 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.64771\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 053 | loss: 0.64771 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.64568\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 054 | loss: 0.64568 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.64150\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 055 | loss: 0.64150 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.64150\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 056 | loss: 0.64150 - acc: 0.7143 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.63715\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 057 | loss: 0.63715 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.63715\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 058 | loss: 0.63715 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.63490\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 059 | loss: 0.63490 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.63259\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 060 | loss: 0.63259 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.63023\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 061 | loss: 0.63023 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.63025\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 062 | loss: 0.63025 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.62747\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 063 | loss: 0.62747 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.62469\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 064 | loss: 0.62469 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.62189\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 065 | loss: 0.62189 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.62209\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 066 | loss: 0.62209 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.61888\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 067 | loss: 0.61888 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.61570\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 068 | loss: 0.61570 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.61253\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 069 | loss: 0.61253 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.60936\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 070 | loss: 0.60936 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.60617\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 071 | loss: 0.60617 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.60297\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 072 | loss: 0.60297 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.60047\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 073 | loss: 0.60047 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.60047\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 074 | loss: 0.60047 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.59676\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 075 | loss: 0.59676 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.59759\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 076 | loss: 0.59759 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.59347\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 077 | loss: 0.59347 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.59365\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 078 | loss: 0.59365 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.59365\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 079 | loss: 0.59365 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.58897\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 080 | loss: 0.58897 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.58444\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 081 | loss: 0.58444 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.58003\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 082 | loss: 0.58003 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.57568\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 083 | loss: 0.57568 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.57137\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 084 | loss: 0.57137 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.56709\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 085 | loss: 0.56709 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.56282\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 086 | loss: 0.56282 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.55857\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 087 | loss: 0.55857 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.55007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 088 | loss: 0.55007 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.55007\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 089 | loss: 0.55007 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.54582\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 090 | loss: 0.54582 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.54156\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 091 | loss: 0.54156 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.53729\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 092 | loss: 0.53729 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.53301\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 093 | loss: 0.53301 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.52872\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 094 | loss: 0.52872 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.52441\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 095 | loss: 0.52441 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.52010\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 096 | loss: 0.52010 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.51144\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 097 | loss: 0.51144 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.51144\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 098 | loss: 0.51144 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.50710\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 099 | loss: 0.50710 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.50274\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 100 | loss: 0.50274 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.49838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 101 | loss: 0.49838 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.50520\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 102 | loss: 0.50520 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.49975\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 103 | loss: 0.49975 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.50569\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 104 | loss: 0.50569 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.49941\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 105 | loss: 0.49941 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.49337\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 106 | loss: 0.49337 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.48190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 107 | loss: 0.48190 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.47642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 108 | loss: 0.47642 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.47109\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 109 | loss: 0.47109 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.47109\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 110 | loss: 0.47109 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.46587\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 111 | loss: 0.46587 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.46075\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 112 | loss: 0.46075 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.45572\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 113 | loss: 0.45572 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.45077\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 114 | loss: 0.45077 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.44587\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 115 | loss: 0.44587 - acc: 0.7143 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.44103\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 116 | loss: 0.44103 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.43622\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 117 | loss: 0.43622 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.43144\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 118 | loss: 0.43144 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.42668\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 119 | loss: 0.42668 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.42193\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 120 | loss: 0.42193 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.41719\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 121 | loss: 0.41719 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.41245\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 122 | loss: 0.41245 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.40770\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 123 | loss: 0.40770 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.40295\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 124 | loss: 0.40295 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.39818\u001b[0m\u001b[0m | time: 0.020s\n",
      "| Adam | epoch: 125 | loss: 0.39818 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.41371\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 126 | loss: 0.41371 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.40692\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 127 | loss: 0.40692 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.40035\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 128 | loss: 0.40035 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.38776\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 129 | loss: 0.38776 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.38776\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 130 | loss: 0.38776 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.38168\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 131 | loss: 0.38168 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.37572\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 132 | loss: 0.37572 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.36986\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 133 | loss: 0.36986 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.36409\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 134 | loss: 0.36409 - acc: 0.7143 -- iter: 7/7\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.35838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 135 | loss: 0.35838 - acc: 0.7286 -- iter: 7/7\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.35273\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 136 | loss: 0.35273 - acc: 0.7414 -- iter: 7/7\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.34713\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 137 | loss: 0.34713 - acc: 0.7530 -- iter: 7/7\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.34157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 138 | loss: 0.34157 - acc: 0.7777 -- iter: 7/7\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.33604\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 139 | loss: 0.33604 - acc: 0.7999 -- iter: 7/7\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.33054\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 140 | loss: 0.33054 - acc: 0.8199 -- iter: 7/7\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.32506\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 141 | loss: 0.32506 - acc: 0.8379 -- iter: 7/7\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.31961\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 142 | loss: 0.31961 - acc: 0.8541 -- iter: 7/7\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.30874\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 143 | loss: 0.30874 - acc: 0.8687 -- iter: 7/7\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.30332\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 144 | loss: 0.30332 - acc: 0.8819 -- iter: 7/7\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.29792\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 145 | loss: 0.29792 - acc: 0.8937 -- iter: 7/7\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.29253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 146 | loss: 0.29253 - acc: 0.9043 -- iter: 7/7\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.28716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 147 | loss: 0.28716 - acc: 0.9139 -- iter: 7/7\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.28180\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 148 | loss: 0.28180 - acc: 0.9225 -- iter: 7/7\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.28180\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 149 | loss: 0.28180 - acc: 0.9302 -- iter: 7/7\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.27645\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 150 | loss: 0.27645 - acc: 0.9372 -- iter: 7/7\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.27113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 151 | loss: 0.27113 - acc: 0.9435 -- iter: 7/7\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.26582\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 152 | loss: 0.26582 - acc: 0.9491 -- iter: 7/7\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.25528\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 153 | loss: 0.25528 - acc: 0.9542 -- iter: 7/7\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.25005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 154 | loss: 0.25005 - acc: 0.9588 -- iter: 7/7\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.25005\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 155 | loss: 0.25005 - acc: 0.9629 -- iter: 7/7\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.28617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 156 | loss: 0.28617 - acc: 0.9381 -- iter: 7/7\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.27695\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 157 | loss: 0.27695 - acc: 0.9443 -- iter: 7/7\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.26825\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 158 | loss: 0.26825 - acc: 0.9498 -- iter: 7/7\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.26001\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 159 | loss: 0.26001 - acc: 0.9548 -- iter: 7/7\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.25218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 160 | loss: 0.25218 - acc: 0.9594 -- iter: 7/7\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.24473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 161 | loss: 0.24473 - acc: 0.9634 -- iter: 7/7\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.32822\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 162 | loss: 0.32822 - acc: 0.9099 -- iter: 7/7\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.31251\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 163 | loss: 0.31251 - acc: 0.9189 -- iter: 7/7\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.29812\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 164 | loss: 0.29812 - acc: 0.9271 -- iter: 7/7\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.28490\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 165 | loss: 0.28490 - acc: 0.9343 -- iter: 7/7\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.30239\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 166 | loss: 0.30239 - acc: 0.9123 -- iter: 7/7\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.30239\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 167 | loss: 0.30239 - acc: 0.9211 -- iter: 7/7\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.28804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 168 | loss: 0.28804 - acc: 0.9290 -- iter: 7/7\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.31026\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 169 | loss: 0.31026 - acc: 0.9361 -- iter: 7/7\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.31026\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 170 | loss: 0.31026 - acc: 0.9139 -- iter: 7/7\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.29445\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 171 | loss: 0.29445 - acc: 0.9225 -- iter: 7/7\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.32811\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 172 | loss: 0.32811 - acc: 0.9017 -- iter: 7/7\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.34469\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 173 | loss: 0.34469 - acc: 0.9115 -- iter: 7/7\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.32485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 174 | loss: 0.32485 - acc: 0.8918 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.32485\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 175 | loss: 0.32485 - acc: 0.9026 -- iter: 7/7\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.30687\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 176 | loss: 0.30687 - acc: 0.9124 -- iter: 7/7\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.29055\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 177 | loss: 0.29055 - acc: 0.9211 -- iter: 7/7\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.27569\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 178 | loss: 0.27569 - acc: 0.9290 -- iter: 7/7\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.26215\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 179 | loss: 0.26215 - acc: 0.9361 -- iter: 7/7\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.23844\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 180 | loss: 0.23844 - acc: 0.9425 -- iter: 7/7\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.23844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 181 | loss: 0.23844 - acc: 0.9483 -- iter: 7/7\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.22803\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 182 | loss: 0.22803 - acc: 0.9534 -- iter: 7/7\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.21845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 183 | loss: 0.21845 - acc: 0.9581 -- iter: 7/7\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.20961\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 184 | loss: 0.20961 - acc: 0.9623 -- iter: 7/7\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.19382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 185 | loss: 0.19382 - acc: 0.9660 -- iter: 7/7\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.19382\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 186 | loss: 0.19382 - acc: 0.9694 -- iter: 7/7\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.18675\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 187 | loss: 0.18675 - acc: 0.9725 -- iter: 7/7\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.18015\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 188 | loss: 0.18015 - acc: 0.9752 -- iter: 7/7\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.17398\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 189 | loss: 0.17398 - acc: 0.9777 -- iter: 7/7\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.16818\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 190 | loss: 0.16818 - acc: 0.9800 -- iter: 7/7\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.16274\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 191 | loss: 0.16274 - acc: 0.9820 -- iter: 7/7\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.15760\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 192 | loss: 0.15760 - acc: 0.9838 -- iter: 7/7\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.15274\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 193 | loss: 0.15274 - acc: 0.9854 -- iter: 7/7\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.14814\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 194 | loss: 0.14814 - acc: 0.9868 -- iter: 7/7\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.14377\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 195 | loss: 0.14377 - acc: 0.9893 -- iter: 7/7\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.13961\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 196 | loss: 0.13961 - acc: 0.9893 -- iter: 7/7\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.13564\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 197 | loss: 0.13564 - acc: 0.9904 -- iter: 7/7\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.13185\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 198 | loss: 0.13185 - acc: 0.9914 -- iter: 7/7\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.12823\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 199 | loss: 0.12823 - acc: 0.9922 -- iter: 7/7\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.12476\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 200 | loss: 0.12476 - acc: 0.9930 -- iter: 7/7\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.12142\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 201 | loss: 0.12142 - acc: 0.9937 -- iter: 7/7\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.11822\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 202 | loss: 0.11822 - acc: 0.9943 -- iter: 7/7\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.11513\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 203 | loss: 0.11513 - acc: 0.9949 -- iter: 7/7\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.11216\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 204 | loss: 0.11216 - acc: 0.9954 -- iter: 7/7\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.10930\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 205 | loss: 0.10930 - acc: 0.9959 -- iter: 7/7\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.10653\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 206 | loss: 0.10653 - acc: 0.9963 -- iter: 7/7\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.10386\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 207 | loss: 0.10386 - acc: 0.9967 -- iter: 7/7\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.10127\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 208 | loss: 0.10127 - acc: 0.9970 -- iter: 7/7\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.09878\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 209 | loss: 0.09878 - acc: 0.9973 -- iter: 7/7\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.09636\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 210 | loss: 0.09636 - acc: 0.9976 -- iter: 7/7\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.09401\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 211 | loss: 0.09401 - acc: 0.9978 -- iter: 7/7\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.09174\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 212 | loss: 0.09174 - acc: 0.9980 -- iter: 7/7\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.08954\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 213 | loss: 0.08954 - acc: 0.9982 -- iter: 7/7\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.15984\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 214 | loss: 0.15984 - acc: 0.9698 -- iter: 7/7\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.15058\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 215 | loss: 0.15058 - acc: 0.9728 -- iter: 7/7\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.14216\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 216 | loss: 0.14216 - acc: 0.9756 -- iter: 7/7\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.13448\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 217 | loss: 0.13448 - acc: 0.9780 -- iter: 7/7\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.12747\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 218 | loss: 0.12747 - acc: 0.9802 -- iter: 7/7\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.12106\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 219 | loss: 0.12106 - acc: 0.9822 -- iter: 7/7\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.11519\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 220 | loss: 0.11519 - acc: 0.9840 -- iter: 7/7\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.10981\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 221 | loss: 0.10981 - acc: 0.9856 -- iter: 7/7\n",
      "--\n",
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.10486\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 222 | loss: 0.10486 - acc: 0.9870 -- iter: 7/7\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.10031\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 223 | loss: 0.10031 - acc: 0.9883 -- iter: 7/7\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.09611\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 224 | loss: 0.09611 - acc: 0.9895 -- iter: 7/7\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.09222\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 225 | loss: 0.09222 - acc: 0.9905 -- iter: 7/7\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.16455\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 226 | loss: 0.16455 - acc: 0.9629 -- iter: 7/7\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.15368\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 227 | loss: 0.15368 - acc: 0.9666 -- iter: 7/7\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.14384\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 228 | loss: 0.14384 - acc: 0.9700 -- iter: 7/7\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.13493\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 229 | loss: 0.13493 - acc: 0.9730 -- iter: 7/7\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.12686\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 230 | loss: 0.12686 - acc: 0.9757 -- iter: 7/7\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.11953\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 231 | loss: 0.11953 - acc: 0.9781 -- iter: 7/7\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.11287\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 232 | loss: 0.11287 - acc: 0.9803 -- iter: 7/7\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.10680\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 233 | loss: 0.10680 - acc: 0.9823 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.18776\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 234 | loss: 0.18776 - acc: 0.9555 -- iter: 7/7\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.17412\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 235 | loss: 0.17412 - acc: 0.9599 -- iter: 7/7\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.16182\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 236 | loss: 0.16182 - acc: 0.9639 -- iter: 7/7\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.15072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 237 | loss: 0.15072 - acc: 0.9675 -- iter: 7/7\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.14069\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 238 | loss: 0.14069 - acc: 0.9708 -- iter: 7/7\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.13163\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 239 | loss: 0.13163 - acc: 0.9763 -- iter: 7/7\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.12343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 240 | loss: 0.12343 - acc: 0.9763 -- iter: 7/7\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.11600\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 241 | loss: 0.11600 - acc: 0.9787 -- iter: 7/7\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.19644\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 242 | loss: 0.19644 - acc: 0.9570 -- iter: 7/7\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.16833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 243 | loss: 0.16833 - acc: 0.9570 -- iter: 7/7\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.16833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 244 | loss: 0.16833 - acc: 0.9613 -- iter: 7/7\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.14548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 245 | loss: 0.14548 - acc: 0.9652 -- iter: 7/7\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.14548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 246 | loss: 0.14548 - acc: 0.9687 -- iter: 7/7\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.13570\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 247 | loss: 0.13570 - acc: 0.9718 -- iter: 7/7\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.12686\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 248 | loss: 0.12686 - acc: 0.9746 -- iter: 7/7\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.11886\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 249 | loss: 0.11886 - acc: 0.9772 -- iter: 7/7\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.25654\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 250 | loss: 0.25654 - acc: 0.9223 -- iter: 7/7\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.25654\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 251 | loss: 0.25654 - acc: 0.9301 -- iter: 7/7\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.23561\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 252 | loss: 0.23561 - acc: 0.9371 -- iter: 7/7\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.21679\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 253 | loss: 0.21679 - acc: 0.9434 -- iter: 7/7\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.19987\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 254 | loss: 0.19987 - acc: 0.9490 -- iter: 7/7\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.18464\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 255 | loss: 0.18464 - acc: 0.9541 -- iter: 7/7\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.17093\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 256 | loss: 0.17093 - acc: 0.9587 -- iter: 7/7\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.15859\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 257 | loss: 0.15859 - acc: 0.9628 -- iter: 7/7\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.22822\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 258 | loss: 0.22822 - acc: 0.9380 -- iter: 7/7\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.21015\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 259 | loss: 0.21015 - acc: 0.9442 -- iter: 7/7\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.27875\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 260 | loss: 0.27875 - acc: 0.9212 -- iter: 7/7\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.25568\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 261 | loss: 0.25568 - acc: 0.9291 -- iter: 7/7\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.23495\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 262 | loss: 0.23495 - acc: 0.9362 -- iter: 7/7\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.21632\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 263 | loss: 0.21632 - acc: 0.9426 -- iter: 7/7\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.19956\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 264 | loss: 0.19956 - acc: 0.9483 -- iter: 7/7\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.18448\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 265 | loss: 0.18448 - acc: 0.9535 -- iter: 7/7\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.17091\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 266 | loss: 0.17091 - acc: 0.9581 -- iter: 7/7\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.15869\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 267 | loss: 0.15869 - acc: 0.9623 -- iter: 7/7\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.14767\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 268 | loss: 0.14767 - acc: 0.9661 -- iter: 7/7\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.13774\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 269 | loss: 0.13774 - acc: 0.9695 -- iter: 7/7\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.12877\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 270 | loss: 0.12877 - acc: 0.9725 -- iter: 7/7\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.12067\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 271 | loss: 0.12067 - acc: 0.9753 -- iter: 7/7\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.11335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 272 | loss: 0.11335 - acc: 0.9777 -- iter: 7/7\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.10672\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 273 | loss: 0.10672 - acc: 0.9800 -- iter: 7/7\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.18074\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 274 | loss: 0.18074 - acc: 0.9534 -- iter: 7/7\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.16733\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 275 | loss: 0.16733 - acc: 0.9581 -- iter: 7/7\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.15525\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 276 | loss: 0.15525 - acc: 0.9623 -- iter: 7/7\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.14436\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 277 | loss: 0.14436 - acc: 0.9660 -- iter: 7/7\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.13455\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 278 | loss: 0.13455 - acc: 0.9694 -- iter: 7/7\n",
      "--\n",
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.12569\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 279 | loss: 0.12569 - acc: 0.9725 -- iter: 7/7\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.11046\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 280 | loss: 0.11046 - acc: 0.9752 -- iter: 7/7\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.11046\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 281 | loss: 0.11046 - acc: 0.9777 -- iter: 7/7\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.10392\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 282 | loss: 0.10392 - acc: 0.9799 -- iter: 7/7\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.09799\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 283 | loss: 0.09799 - acc: 0.9838 -- iter: 7/7\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.09262\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 284 | loss: 0.09262 - acc: 0.9838 -- iter: 7/7\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.08774\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 285 | loss: 0.08774 - acc: 0.9854 -- iter: 7/7\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.16434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 286 | loss: 0.16434 - acc: 0.9583 -- iter: 7/7\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.15224\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 287 | loss: 0.15224 - acc: 0.9624 -- iter: 7/7\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.14134\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 288 | loss: 0.14134 - acc: 0.9696 -- iter: 7/7\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.13151\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 289 | loss: 0.13151 - acc: 0.9696 -- iter: 7/7\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.12265\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 290 | loss: 0.12265 - acc: 0.9726 -- iter: 7/7\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.10742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 291 | loss: 0.10742 - acc: 0.9754 -- iter: 7/7\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.10742\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 292 | loss: 0.10742 - acc: 0.9778 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.10088\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 293 | loss: 0.10088 - acc: 0.9800 -- iter: 7/7\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.18634\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 294 | loss: 0.18634 - acc: 0.9535 -- iter: 7/7\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.17189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 295 | loss: 0.17189 - acc: 0.9581 -- iter: 7/7\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.15888\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 296 | loss: 0.15888 - acc: 0.9623 -- iter: 7/7\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.14716\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 297 | loss: 0.14716 - acc: 0.9661 -- iter: 7/7\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.13660\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 298 | loss: 0.13660 - acc: 0.9695 -- iter: 7/7\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.12709\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 299 | loss: 0.12709 - acc: 0.9725 -- iter: 7/7\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.11851\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 300 | loss: 0.11851 - acc: 0.9753 -- iter: 7/7\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.11076\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 301 | loss: 0.11076 - acc: 0.9777 -- iter: 7/7\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.09743\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 302 | loss: 0.09743 - acc: 0.9800 -- iter: 7/7\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.09743\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 303 | loss: 0.09743 - acc: 0.9820 -- iter: 7/7\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.08652\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 304 | loss: 0.08652 - acc: 0.9838 -- iter: 7/7\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.08182\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 305 | loss: 0.08182 - acc: 0.9854 -- iter: 7/7\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.07755\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 306 | loss: 0.07755 - acc: 0.9869 -- iter: 7/7\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.07755\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 307 | loss: 0.07755 - acc: 0.9882 -- iter: 7/7\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.07368\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 308 | loss: 0.07368 - acc: 0.9894 -- iter: 7/7\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.07015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 309 | loss: 0.07015 - acc: 0.9904 -- iter: 7/7\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.06400\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 310 | loss: 0.06400 - acc: 0.9914 -- iter: 7/7\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.06400\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 311 | loss: 0.06400 - acc: 0.9922 -- iter: 7/7\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.06132\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 312 | loss: 0.06132 - acc: 0.9930 -- iter: 7/7\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.05886\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 313 | loss: 0.05886 - acc: 0.9937 -- iter: 7/7\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.05661\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 314 | loss: 0.05661 - acc: 0.9943 -- iter: 7/7\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.05454\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 315 | loss: 0.05454 - acc: 0.9949 -- iter: 7/7\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.05264\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 316 | loss: 0.05264 - acc: 0.9954 -- iter: 7/7\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.05089\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 317 | loss: 0.05089 - acc: 0.9963 -- iter: 7/7\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.04927\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 318 | loss: 0.04927 - acc: 0.9963 -- iter: 7/7\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.04777\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 319 | loss: 0.04777 - acc: 0.9967 -- iter: 7/7\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.04638\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 320 | loss: 0.04638 - acc: 0.9970 -- iter: 7/7\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.04509\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 321 | loss: 0.04509 - acc: 0.9973 -- iter: 7/7\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.04388\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 322 | loss: 0.04388 - acc: 0.9976 -- iter: 7/7\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.04276\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 323 | loss: 0.04276 - acc: 0.9978 -- iter: 7/7\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.13577\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 324 | loss: 0.13577 - acc: 0.9725 -- iter: 7/7\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.12541\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 325 | loss: 0.12541 - acc: 0.9725 -- iter: 7/7\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.30311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 326 | loss: 0.30311 - acc: 0.9181 -- iter: 7/7\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.27607\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 327 | loss: 0.27607 - acc: 0.9263 -- iter: 7/7\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.34760\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 328 | loss: 0.34760 - acc: 0.9051 -- iter: 7/7\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.31621\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 329 | loss: 0.31621 - acc: 0.9146 -- iter: 7/7\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.46904\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 330 | loss: 0.46904 - acc: 0.8660 -- iter: 7/7\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.42568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 331 | loss: 0.42568 - acc: 0.8794 -- iter: 7/7\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.38676\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 332 | loss: 0.38676 - acc: 0.8915 -- iter: 7/7\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.32043\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 333 | loss: 0.32043 - acc: 0.9023 -- iter: 7/7\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.32043\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 334 | loss: 0.32043 - acc: 0.9121 -- iter: 7/7\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.29225\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 335 | loss: 0.29225 - acc: 0.9209 -- iter: 7/7\n",
      "--\n",
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.26694\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 336 | loss: 0.26694 - acc: 0.9288 -- iter: 7/7\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.24421\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 337 | loss: 0.24421 - acc: 0.9359 -- iter: 7/7\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.22379\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 338 | loss: 0.22379 - acc: 0.9423 -- iter: 7/7\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.20544\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 339 | loss: 0.20544 - acc: 0.9481 -- iter: 7/7\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.18894\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 340 | loss: 0.18894 - acc: 0.9533 -- iter: 7/7\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.17411\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 341 | loss: 0.17411 - acc: 0.9579 -- iter: 7/7\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.16076\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 342 | loss: 0.16076 - acc: 0.9622 -- iter: 7/7\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.13794\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 343 | loss: 0.13794 - acc: 0.9659 -- iter: 7/7\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.13794\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 344 | loss: 0.13794 - acc: 0.9693 -- iter: 7/7\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.12821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 345 | loss: 0.12821 - acc: 0.9724 -- iter: 7/7\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.30029\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 346 | loss: 0.30029 - acc: 0.9180 -- iter: 7/7\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.27436\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 347 | loss: 0.27436 - acc: 0.9262 -- iter: 7/7\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.25107\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 348 | loss: 0.25107 - acc: 0.9336 -- iter: 7/7\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.23013\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 349 | loss: 0.23013 - acc: 0.9402 -- iter: 7/7\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.21132\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 350 | loss: 0.21132 - acc: 0.9462 -- iter: 7/7\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.19441\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 351 | loss: 0.19441 - acc: 0.9516 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.17920\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 352 | loss: 0.17920 - acc: 0.9564 -- iter: 7/7\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.15320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 353 | loss: 0.15320 - acc: 0.9608 -- iter: 7/7\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.15320\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 354 | loss: 0.15320 - acc: 0.9647 -- iter: 7/7\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.14212\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 355 | loss: 0.14212 - acc: 0.9682 -- iter: 7/7\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.13213\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 356 | loss: 0.13213 - acc: 0.9714 -- iter: 7/7\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.12313\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 357 | loss: 0.12313 - acc: 0.9743 -- iter: 7/7\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.20021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 358 | loss: 0.20021 - acc: 0.9483 -- iter: 7/7\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.18440\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 359 | loss: 0.18440 - acc: 0.9534 -- iter: 7/7\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.17018\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 360 | loss: 0.17018 - acc: 0.9581 -- iter: 7/7\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.22625\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 361 | loss: 0.22625 - acc: 0.9623 -- iter: 7/7\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.22625\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 362 | loss: 0.22625 - acc: 0.9375 -- iter: 7/7\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.20787\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 363 | loss: 0.20787 - acc: 0.9437 -- iter: 7/7\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.19133\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 364 | loss: 0.19133 - acc: 0.9494 -- iter: 7/7\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.17647\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 365 | loss: 0.17647 - acc: 0.9544 -- iter: 7/7\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.15105\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 366 | loss: 0.15105 - acc: 0.9590 -- iter: 7/7\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.15105\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 367 | loss: 0.15105 - acc: 0.9631 -- iter: 7/7\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.14021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 368 | loss: 0.14021 - acc: 0.9668 -- iter: 7/7\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.13044\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 369 | loss: 0.13044 - acc: 0.9159 -- iter: 7/7\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.30271\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 370 | loss: 0.30271 - acc: 0.9159 -- iter: 7/7\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.27672\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 371 | loss: 0.27672 - acc: 0.9244 -- iter: 7/7\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.25338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 372 | loss: 0.25338 - acc: 0.9319 -- iter: 7/7\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.23241\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 373 | loss: 0.23241 - acc: 0.9387 -- iter: 7/7\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.29234\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 374 | loss: 0.29234 - acc: 0.9163 -- iter: 7/7\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.26754\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 375 | loss: 0.26754 - acc: 0.9247 -- iter: 7/7\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.24526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 376 | loss: 0.24526 - acc: 0.9322 -- iter: 7/7\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.22524\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 377 | loss: 0.22524 - acc: 0.9390 -- iter: 7/7\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.20725\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 378 | loss: 0.20725 - acc: 0.9451 -- iter: 7/7\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.19107\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 379 | loss: 0.19107 - acc: 0.9506 -- iter: 7/7\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.17652\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 380 | loss: 0.17652 - acc: 0.9555 -- iter: 7/7\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.16342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 381 | loss: 0.16342 - acc: 0.9600 -- iter: 7/7\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.32599\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 382 | loss: 0.32599 - acc: 0.9068 -- iter: 7/7\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.29800\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 383 | loss: 0.29800 - acc: 0.9161 -- iter: 7/7\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.27286\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 384 | loss: 0.27286 - acc: 0.9245 -- iter: 7/7\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.25028\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 385 | loss: 0.25028 - acc: 0.9321 -- iter: 7/7\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.31534\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 386 | loss: 0.31534 - acc: 0.9103 -- iter: 7/7\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.28859\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 387 | loss: 0.28859 - acc: 0.9193 -- iter: 7/7\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.26456\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 388 | loss: 0.26456 - acc: 0.9273 -- iter: 7/7\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.24297\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 389 | loss: 0.24297 - acc: 0.9346 -- iter: 7/7\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.30750\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 390 | loss: 0.30750 - acc: 0.9126 -- iter: 7/7\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.28170\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 391 | loss: 0.28170 - acc: 0.9213 -- iter: 7/7\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.25851\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 392 | loss: 0.25851 - acc: 0.9292 -- iter: 7/7\n",
      "--\n",
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.21896\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 393 | loss: 0.21896 - acc: 0.9363 -- iter: 7/7\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.21896\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 394 | loss: 0.21896 - acc: 0.9426 -- iter: 7/7\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.20212\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 395 | loss: 0.20212 - acc: 0.9484 -- iter: 7/7\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.26870\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 396 | loss: 0.26870 - acc: 0.9250 -- iter: 7/7\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.24693\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 397 | loss: 0.24693 - acc: 0.9325 -- iter: 7/7\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.22736\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 398 | loss: 0.22736 - acc: 0.9392 -- iter: 7/7\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.20977\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 399 | loss: 0.20977 - acc: 0.9453 -- iter: 7/7\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.17971\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 400 | loss: 0.17971 - acc: 0.9508 -- iter: 7/7\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.16690\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 401 | loss: 0.16690 - acc: 0.9557 -- iter: 7/7\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.15535\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 402 | loss: 0.15535 - acc: 0.9601 -- iter: 7/7\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.14495\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 403 | loss: 0.14495 - acc: 0.9641 -- iter: 7/7\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.13557\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 404 | loss: 0.13557 - acc: 0.9677 -- iter: 7/7\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.13557\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 405 | loss: 0.13557 - acc: 0.9709 -- iter: 7/7\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.12710\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 406 | loss: 0.12710 - acc: 0.9738 -- iter: 7/7\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.11945\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 407 | loss: 0.11945 - acc: 0.9765 -- iter: 7/7\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.11254\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 408 | loss: 0.11254 - acc: 0.9788 -- iter: 7/7\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.10629\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 409 | loss: 0.10629 - acc: 0.9809 -- iter: 7/7\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.18238\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 410 | loss: 0.18238 - acc: 0.9543 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.16910\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 411 | loss: 0.16910 - acc: 0.9588 -- iter: 7/7\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.15715\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 412 | loss: 0.15715 - acc: 0.9630 -- iter: 7/7\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.14637\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 413 | loss: 0.14637 - acc: 0.9667 -- iter: 7/7\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.13666\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 414 | loss: 0.13666 - acc: 0.9700 -- iter: 7/7\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.12789\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 415 | loss: 0.12789 - acc: 0.9730 -- iter: 7/7\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.11998\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 416 | loss: 0.11998 - acc: 0.9757 -- iter: 7/7\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.11283\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 417 | loss: 0.11283 - acc: 0.9781 -- iter: 7/7\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.10637\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 418 | loss: 0.10637 - acc: 0.9803 -- iter: 7/7\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.10051\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 419 | loss: 0.10051 - acc: 0.9823 -- iter: 7/7\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.09521\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 420 | loss: 0.09521 - acc: 0.9841 -- iter: 7/7\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.09040\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 421 | loss: 0.09040 - acc: 0.9856 -- iter: 7/7\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.08207\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 422 | loss: 0.08207 - acc: 0.9871 -- iter: 7/7\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.08207\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 423 | loss: 0.08207 - acc: 0.9884 -- iter: 7/7\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.07845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 424 | loss: 0.07845 - acc: 0.9895 -- iter: 7/7\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.07516\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 425 | loss: 0.07516 - acc: 0.9906 -- iter: 7/7\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.07215\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 426 | loss: 0.07215 - acc: 0.9915 -- iter: 7/7\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.06940\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 427 | loss: 0.06940 - acc: 0.9924 -- iter: 7/7\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.06688\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 428 | loss: 0.06688 - acc: 0.9931 -- iter: 7/7\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.06457\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 429 | loss: 0.06457 - acc: 0.9938 -- iter: 7/7\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.23869\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 430 | loss: 0.23869 - acc: 0.9373 -- iter: 7/7\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.20163\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 431 | loss: 0.20163 - acc: 0.9436 -- iter: 7/7\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.20163\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 432 | loss: 0.20163 - acc: 0.9492 -- iter: 7/7\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.18584\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 433 | loss: 0.18584 - acc: 0.9543 -- iter: 7/7\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.25504\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 434 | loss: 0.25504 - acc: 0.9303 -- iter: 7/7\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.23395\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 435 | loss: 0.23395 - acc: 0.9373 -- iter: 7/7\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.30451\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 436 | loss: 0.30451 - acc: 0.9150 -- iter: 7/7\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.27853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 437 | loss: 0.27853 - acc: 0.9235 -- iter: 7/7\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.25519\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 438 | loss: 0.25519 - acc: 0.9311 -- iter: 7/7\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.23422\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 439 | loss: 0.23422 - acc: 0.9380 -- iter: 7/7\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.21536\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 440 | loss: 0.21536 - acc: 0.9442 -- iter: 7/7\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.18315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 441 | loss: 0.18315 - acc: 0.9498 -- iter: 7/7\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.18315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 442 | loss: 0.18315 - acc: 0.9548 -- iter: 7/7\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.16942\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 443 | loss: 0.16942 - acc: 0.9593 -- iter: 7/7\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.15706\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 444 | loss: 0.15706 - acc: 0.9634 -- iter: 7/7\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.13590\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 445 | loss: 0.13590 - acc: 0.9671 -- iter: 7/7\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.12686\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 446 | loss: 0.12686 - acc: 0.9703 -- iter: 7/7\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.12686\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 447 | loss: 0.12686 - acc: 0.9733 -- iter: 7/7\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.11134\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 448 | loss: 0.11134 - acc: 0.9760 -- iter: 7/7\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.11134\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 449 | loss: 0.11134 - acc: 0.9784 -- iter: 7/7\n",
      "--\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.10469\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 450 | loss: 0.10469 - acc: 0.9805 -- iter: 7/7\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.09867\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 451 | loss: 0.09867 - acc: 0.9825 -- iter: 7/7\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.09323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 452 | loss: 0.09323 - acc: 0.9842 -- iter: 7/7\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.08830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 453 | loss: 0.08830 - acc: 0.9858 -- iter: 7/7\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.08383\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 454 | loss: 0.08383 - acc: 0.9872 -- iter: 7/7\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.07977\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 455 | loss: 0.07977 - acc: 0.9885 -- iter: 7/7\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.07608\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 456 | loss: 0.07608 - acc: 0.9897 -- iter: 7/7\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.07273\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 457 | loss: 0.07273 - acc: 0.9907 -- iter: 7/7\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.24584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 458 | loss: 0.24584 - acc: 0.9345 -- iter: 7/7\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.22549\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 459 | loss: 0.22549 - acc: 0.9410 -- iter: 7/7\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.20720\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 460 | loss: 0.20720 - acc: 0.9469 -- iter: 7/7\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.19076\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 461 | loss: 0.19076 - acc: 0.9522 -- iter: 7/7\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.17596\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 462 | loss: 0.17596 - acc: 0.9570 -- iter: 7/7\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.16264\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 463 | loss: 0.16264 - acc: 0.9613 -- iter: 7/7\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.15065\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 464 | loss: 0.15065 - acc: 0.9652 -- iter: 7/7\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.13986\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 465 | loss: 0.13986 - acc: 0.9687 -- iter: 7/7\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.13013\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 466 | loss: 0.13013 - acc: 0.9718 -- iter: 7/7\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.12136\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 467 | loss: 0.12136 - acc: 0.9746 -- iter: 7/7\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.11344\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 468 | loss: 0.11344 - acc: 0.9772 -- iter: 7/7\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.10630\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 469 | loss: 0.10630 - acc: 0.9794 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.09985\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 470 | loss: 0.09985 - acc: 0.9815 -- iter: 7/7\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.09403\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 471 | loss: 0.09403 - acc: 0.9833 -- iter: 7/7\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.08875\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 472 | loss: 0.08875 - acc: 0.9850 -- iter: 7/7\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.08398\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 473 | loss: 0.08398 - acc: 0.9865 -- iter: 7/7\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.07965\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 474 | loss: 0.07965 - acc: 0.9879 -- iter: 7/7\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.24908\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 475 | loss: 0.24908 - acc: 0.9891 -- iter: 7/7\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.24908\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 476 | loss: 0.24908 - acc: 0.9330 -- iter: 7/7\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.22821\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 477 | loss: 0.22821 - acc: 0.9397 -- iter: 7/7\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.20944\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 478 | loss: 0.20944 - acc: 0.9457 -- iter: 7/7\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.19257\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 479 | loss: 0.19257 - acc: 0.9512 -- iter: 7/7\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.16374\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 480 | loss: 0.16374 - acc: 0.9561 -- iter: 7/7\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.16374\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 481 | loss: 0.16374 - acc: 0.9605 -- iter: 7/7\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.15146\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 482 | loss: 0.15146 - acc: 0.9644 -- iter: 7/7\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.14039\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 483 | loss: 0.14039 - acc: 0.9680 -- iter: 7/7\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.12145\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 484 | loss: 0.12145 - acc: 0.9712 -- iter: 7/7\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.11335\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 485 | loss: 0.11335 - acc: 0.9741 -- iter: 7/7\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.11335\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 486 | loss: 0.11335 - acc: 0.9766 -- iter: 7/7\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.10604\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 487 | loss: 0.10604 - acc: 0.9790 -- iter: 7/7\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.09945\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 488 | loss: 0.09945 - acc: 0.9811 -- iter: 7/7\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.09349\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 489 | loss: 0.09349 - acc: 0.9830 -- iter: 7/7\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.08811\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 490 | loss: 0.08811 - acc: 0.9847 -- iter: 7/7\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.08324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 491 | loss: 0.08324 - acc: 0.9862 -- iter: 7/7\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.07883\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 492 | loss: 0.07883 - acc: 0.9876 -- iter: 7/7\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.07483\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 493 | loss: 0.07483 - acc: 0.9888 -- iter: 7/7\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.07120\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 494 | loss: 0.07120 - acc: 0.9899 -- iter: 7/7\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.06791\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 495 | loss: 0.06791 - acc: 0.9910 -- iter: 7/7\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.06491\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 496 | loss: 0.06491 - acc: 0.9919 -- iter: 7/7\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.06219\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 497 | loss: 0.06219 - acc: 0.9927 -- iter: 7/7\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.15504\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 498 | loss: 0.15504 - acc: 0.9648 -- iter: 7/7\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.14327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 499 | loss: 0.14327 - acc: 0.9683 -- iter: 7/7\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.31761\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 500 | loss: 0.31761 - acc: 0.9144 -- iter: 7/7\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.28962\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 501 | loss: 0.28962 - acc: 0.9229 -- iter: 7/7\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.26448\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 502 | loss: 0.26448 - acc: 0.9376 -- iter: 7/7\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.24187\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 503 | loss: 0.24187 - acc: 0.9438 -- iter: 7/7\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.22156\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 504 | loss: 0.22156 - acc: 0.9438 -- iter: 7/7\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.20330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 505 | loss: 0.20330 - acc: 0.9494 -- iter: 7/7\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.17210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 506 | loss: 0.17210 - acc: 0.9545 -- iter: 7/7\n",
      "--\n",
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.15881\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 507 | loss: 0.15881 - acc: 0.9590 -- iter: 7/7\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.15881\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 508 | loss: 0.15881 - acc: 0.9631 -- iter: 7/7\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.14685\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 509 | loss: 0.14685 - acc: 0.9668 -- iter: 7/7\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.13608\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 510 | loss: 0.13608 - acc: 0.9701 -- iter: 7/7\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.12638\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 511 | loss: 0.12638 - acc: 0.9731 -- iter: 7/7\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.11764\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 512 | loss: 0.11764 - acc: 0.9758 -- iter: 7/7\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.10976\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 513 | loss: 0.10976 - acc: 0.9782 -- iter: 7/7\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.10265\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 514 | loss: 0.10265 - acc: 0.9804 -- iter: 7/7\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.09623\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 515 | loss: 0.09623 - acc: 0.9824 -- iter: 7/7\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.09044\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 516 | loss: 0.09044 - acc: 0.9841 -- iter: 7/7\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.08520\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 517 | loss: 0.08520 - acc: 0.9857 -- iter: 7/7\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.08047\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 518 | loss: 0.08047 - acc: 0.9871 -- iter: 7/7\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.07618\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 519 | loss: 0.07618 - acc: 0.9884 -- iter: 7/7\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.25498\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 520 | loss: 0.25498 - acc: 0.9324 -- iter: 7/7\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.23325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 521 | loss: 0.23325 - acc: 0.9392 -- iter: 7/7\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.39521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 522 | loss: 0.39521 - acc: 0.8881 -- iter: 7/7\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.35955\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 523 | loss: 0.35955 - acc: 0.8993 -- iter: 7/7\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.32752\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 524 | loss: 0.32752 - acc: 0.9094 -- iter: 7/7\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.29874\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 525 | loss: 0.29874 - acc: 0.9185 -- iter: 7/7\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.27289\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 526 | loss: 0.27289 - acc: 0.9266 -- iter: 7/7\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.24966\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 527 | loss: 0.24966 - acc: 0.9339 -- iter: 7/7\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.22878\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 528 | loss: 0.22878 - acc: 0.9406 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.21001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 529 | loss: 0.21001 - acc: 0.9465 -- iter: 7/7\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.17796\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 530 | loss: 0.17796 - acc: 0.9518 -- iter: 7/7\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.17796\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 531 | loss: 0.17796 - acc: 0.9567 -- iter: 7/7\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.16431\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 532 | loss: 0.16431 - acc: 0.9610 -- iter: 7/7\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.15202\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 533 | loss: 0.15202 - acc: 0.9649 -- iter: 7/7\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.31871\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 534 | loss: 0.31871 - acc: 0.9113 -- iter: 7/7\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.29103\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 535 | loss: 0.29103 - acc: 0.9201 -- iter: 7/7\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.26616\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 536 | loss: 0.26616 - acc: 0.9281 -- iter: 7/7\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.22372\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 537 | loss: 0.22372 - acc: 0.9353 -- iter: 7/7\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.20566\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 538 | loss: 0.20566 - acc: 0.9418 -- iter: 7/7\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.18942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 539 | loss: 0.18942 - acc: 0.9476 -- iter: 7/7\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.17481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 540 | loss: 0.17481 - acc: 0.9528 -- iter: 7/7\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.16167\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 541 | loss: 0.16167 - acc: 0.9576 -- iter: 7/7\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.16167\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 542 | loss: 0.16167 - acc: 0.9618 -- iter: 7/7\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.14984\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 543 | loss: 0.14984 - acc: 0.9656 -- iter: 7/7\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.22656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 544 | loss: 0.22656 - acc: 0.9405 -- iter: 7/7\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.20825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 545 | loss: 0.20825 - acc: 0.9464 -- iter: 7/7\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.19179\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 546 | loss: 0.19179 - acc: 0.9518 -- iter: 7/7\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.16365\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 547 | loss: 0.16365 - acc: 0.9566 -- iter: 7/7\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.16365\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 548 | loss: 0.16365 - acc: 0.9610 -- iter: 7/7\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.15166\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 549 | loss: 0.15166 - acc: 0.9649 -- iter: 7/7\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.14085\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 550 | loss: 0.14085 - acc: 0.9684 -- iter: 7/7\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.13112\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 551 | loss: 0.13112 - acc: 0.9715 -- iter: 7/7\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.12235\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 552 | loss: 0.12235 - acc: 0.9744 -- iter: 7/7\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.11444\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 553 | loss: 0.11444 - acc: 0.9769 -- iter: 7/7\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.10085\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 554 | loss: 0.10085 - acc: 0.9792 -- iter: 7/7\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.10085\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 555 | loss: 0.10085 - acc: 0.9813 -- iter: 7/7\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.08975\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 556 | loss: 0.08975 - acc: 0.9832 -- iter: 7/7\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.08975\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 557 | loss: 0.08975 - acc: 0.9864 -- iter: 7/7\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.08498\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 558 | loss: 0.08498 - acc: 0.9864 -- iter: 7/7\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.08066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 559 | loss: 0.08066 - acc: 0.9877 -- iter: 7/7\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.07674\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 560 | loss: 0.07674 - acc: 0.9890 -- iter: 7/7\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.07319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 561 | loss: 0.07319 - acc: 0.9901 -- iter: 7/7\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.06995\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 562 | loss: 0.06995 - acc: 0.9911 -- iter: 7/7\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.06701\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 563 | loss: 0.06701 - acc: 0.9920 -- iter: 7/7\n",
      "--\n",
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.06433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 564 | loss: 0.06433 - acc: 0.9928 -- iter: 7/7\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.06188\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 565 | loss: 0.06188 - acc: 0.9935 -- iter: 7/7\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.05965\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 566 | loss: 0.05965 - acc: 0.9941 -- iter: 7/7\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.05760\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 567 | loss: 0.05760 - acc: 0.9947 -- iter: 7/7\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.05573\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 568 | loss: 0.05573 - acc: 0.9953 -- iter: 7/7\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.05400\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 569 | loss: 0.05400 - acc: 0.9957 -- iter: 7/7\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.05242\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 570 | loss: 0.05242 - acc: 0.9962 -- iter: 7/7\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.05096\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 571 | loss: 0.05096 - acc: 0.9965 -- iter: 7/7\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.04961\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 572 | loss: 0.04961 - acc: 0.9969 -- iter: 7/7\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.04836\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 573 | loss: 0.04836 - acc: 0.9972 -- iter: 7/7\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.04720\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 574 | loss: 0.04720 - acc: 0.9975 -- iter: 7/7\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.04612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 575 | loss: 0.04612 - acc: 0.9977 -- iter: 7/7\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.04418\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 576 | loss: 0.04418 - acc: 0.9980 -- iter: 7/7\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.04418\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 577 | loss: 0.04418 - acc: 0.9982 -- iter: 7/7\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.04331\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 578 | loss: 0.04331 - acc: 0.9983 -- iter: 7/7\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.04248\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 579 | loss: 0.04248 - acc: 0.9985 -- iter: 7/7\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.04171\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 580 | loss: 0.04171 - acc: 0.9987 -- iter: 7/7\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.04098\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 581 | loss: 0.04098 - acc: 0.9988 -- iter: 7/7\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.04029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 582 | loss: 0.04029 - acc: 0.9989 -- iter: 7/7\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.03964\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 583 | loss: 0.03964 - acc: 0.9990 -- iter: 7/7\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.03902\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 584 | loss: 0.03902 - acc: 0.9991 -- iter: 7/7\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.03843\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 585 | loss: 0.03843 - acc: 0.9992 -- iter: 7/7\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.03787\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 586 | loss: 0.03787 - acc: 0.9993 -- iter: 7/7\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.03734\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 587 | loss: 0.03734 - acc: 0.9994 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.03633\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 588 | loss: 0.03633 - acc: 0.9994 -- iter: 7/7\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.03633\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 589 | loss: 0.03633 - acc: 0.9995 -- iter: 7/7\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.03586\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 590 | loss: 0.03586 - acc: 0.9995 -- iter: 7/7\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.03541\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 591 | loss: 0.03541 - acc: 0.9996 -- iter: 7/7\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.13013\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 592 | loss: 0.13013 - acc: 0.9710 -- iter: 7/7\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.12022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 593 | loss: 0.12022 - acc: 0.9739 -- iter: 7/7\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.11129\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 594 | loss: 0.11129 - acc: 0.9766 -- iter: 7/7\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.10324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 595 | loss: 0.10324 - acc: 0.9789 -- iter: 7/7\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.09600\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 596 | loss: 0.09600 - acc: 0.9810 -- iter: 7/7\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.08357\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 597 | loss: 0.08357 - acc: 0.9829 -- iter: 7/7\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.08357\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 598 | loss: 0.08357 - acc: 0.9846 -- iter: 7/7\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.07825\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 599 | loss: 0.07825 - acc: 0.9862 -- iter: 7/7\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.07344\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 600 | loss: 0.07344 - acc: 0.9875 -- iter: 7/7\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.06910\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 601 | loss: 0.06910 - acc: 0.9888 -- iter: 7/7\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.25953\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 602 | loss: 0.25953 - acc: 0.9328 -- iter: 7/7\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.23660\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 603 | loss: 0.23660 - acc: 0.9395 -- iter: 7/7\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.21598\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 604 | loss: 0.21598 - acc: 0.9455 -- iter: 7/7\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.19745\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 605 | loss: 0.19745 - acc: 0.9510 -- iter: 7/7\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.18079\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 606 | loss: 0.18079 - acc: 0.9559 -- iter: 7/7\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.16580\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 607 | loss: 0.16580 - acc: 0.9603 -- iter: 7/7\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.15232\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 608 | loss: 0.15232 - acc: 0.9643 -- iter: 7/7\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.14020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 609 | loss: 0.14020 - acc: 0.9678 -- iter: 7/7\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.12929\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 610 | loss: 0.12929 - acc: 0.9711 -- iter: 7/7\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.11946\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 611 | loss: 0.11946 - acc: 0.9740 -- iter: 7/7\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.11062\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 612 | loss: 0.11062 - acc: 0.9766 -- iter: 7/7\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.10266\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 613 | loss: 0.10266 - acc: 0.9789 -- iter: 7/7\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.09548\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 614 | loss: 0.09548 - acc: 0.9810 -- iter: 7/7\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.08901\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 615 | loss: 0.08901 - acc: 0.9829 -- iter: 7/7\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.08318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 616 | loss: 0.08318 - acc: 0.9846 -- iter: 7/7\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.07791\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 617 | loss: 0.07791 - acc: 0.9862 -- iter: 7/7\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.16619\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 618 | loss: 0.16619 - acc: 0.9590 -- iter: 7/7\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.15262\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 619 | loss: 0.15262 - acc: 0.9668 -- iter: 7/7\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.14041\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 620 | loss: 0.14041 - acc: 0.9668 -- iter: 7/7\n",
      "--\n",
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.12943\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 621 | loss: 0.12943 - acc: 0.9701 -- iter: 7/7\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.11954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 622 | loss: 0.11954 - acc: 0.9731 -- iter: 7/7\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.11064\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 623 | loss: 0.11064 - acc: 0.9758 -- iter: 7/7\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.10262\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 624 | loss: 0.10262 - acc: 0.9782 -- iter: 7/7\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.09540\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 625 | loss: 0.09540 - acc: 0.9804 -- iter: 7/7\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.28087\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 626 | loss: 0.28087 - acc: 0.9252 -- iter: 7/7\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.25585\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 627 | loss: 0.25585 - acc: 0.9327 -- iter: 7/7\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.23336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 628 | loss: 0.23336 - acc: 0.9394 -- iter: 7/7\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.21316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 629 | loss: 0.21316 - acc: 0.9455 -- iter: 7/7\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.19499\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 630 | loss: 0.19499 - acc: 0.9509 -- iter: 7/7\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.17865\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 631 | loss: 0.17865 - acc: 0.9558 -- iter: 7/7\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.16396\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 632 | loss: 0.16396 - acc: 0.9602 -- iter: 7/7\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.23270\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 633 | loss: 0.23270 - acc: 0.9642 -- iter: 7/7\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.23270\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 634 | loss: 0.23270 - acc: 0.9392 -- iter: 7/7\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.21265\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 635 | loss: 0.21265 - acc: 0.9453 -- iter: 7/7\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.38162\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 636 | loss: 0.38162 - acc: 0.8936 -- iter: 7/7\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.34676\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 637 | loss: 0.34676 - acc: 0.9043 -- iter: 7/7\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.31544\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 638 | loss: 0.31544 - acc: 0.9138 -- iter: 7/7\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.28731\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 639 | loss: 0.28731 - acc: 0.9225 -- iter: 7/7\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.26203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 640 | loss: 0.26203 - acc: 0.9302 -- iter: 7/7\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.23931\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 641 | loss: 0.23931 - acc: 0.8863 -- iter: 7/7\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.40517\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 642 | loss: 0.40517 - acc: 0.8863 -- iter: 7/7\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.33507\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 643 | loss: 0.33507 - acc: 0.8977 -- iter: 7/7\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.33507\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 644 | loss: 0.33507 - acc: 0.9079 -- iter: 7/7\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.30528\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 645 | loss: 0.30528 - acc: 0.9171 -- iter: 7/7\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.27851\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 646 | loss: 0.27851 - acc: 0.9254 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.25445\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 647 | loss: 0.25445 - acc: 0.9329 -- iter: 7/7\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.23284\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 648 | loss: 0.23284 - acc: 0.9396 -- iter: 7/7\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.21341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 649 | loss: 0.21341 - acc: 0.9456 -- iter: 7/7\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.19594\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 650 | loss: 0.19594 - acc: 0.9511 -- iter: 7/7\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.18024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 651 | loss: 0.18024 - acc: 0.9560 -- iter: 7/7\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.34578\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 652 | loss: 0.34578 - acc: 0.9032 -- iter: 7/7\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.31516\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 653 | loss: 0.31516 - acc: 0.9129 -- iter: 7/7\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.28765\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 654 | loss: 0.28765 - acc: 0.9216 -- iter: 7/7\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.26293\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 655 | loss: 0.26293 - acc: 0.9294 -- iter: 7/7\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.24072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 656 | loss: 0.24072 - acc: 0.9365 -- iter: 7/7\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.22076\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 657 | loss: 0.22076 - acc: 0.9429 -- iter: 7/7\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.20281\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 658 | loss: 0.20281 - acc: 0.9486 -- iter: 7/7\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.18668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 659 | loss: 0.18668 - acc: 0.9537 -- iter: 7/7\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.17216\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 660 | loss: 0.17216 - acc: 0.9583 -- iter: 7/7\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.15910\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 661 | loss: 0.15910 - acc: 0.9625 -- iter: 7/7\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.14735\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 662 | loss: 0.14735 - acc: 0.9663 -- iter: 7/7\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.13677\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 663 | loss: 0.13677 - acc: 0.9696 -- iter: 7/7\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.11865\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 664 | loss: 0.11865 - acc: 0.9727 -- iter: 7/7\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.11865\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 665 | loss: 0.11865 - acc: 0.9754 -- iter: 7/7\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.28365\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 666 | loss: 0.28365 - acc: 0.9207 -- iter: 7/7\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.25945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 667 | loss: 0.25945 - acc: 0.9286 -- iter: 7/7\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.23769\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 668 | loss: 0.23769 - acc: 0.9358 -- iter: 7/7\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.21814\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 669 | loss: 0.21814 - acc: 0.9422 -- iter: 7/7\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.37756\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 670 | loss: 0.37756 - acc: 0.8908 -- iter: 7/7\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.34411\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 671 | loss: 0.34411 - acc: 0.9018 -- iter: 7/7\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.39808\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 672 | loss: 0.39808 - acc: 0.8830 -- iter: 7/7\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.36271\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 673 | loss: 0.36271 - acc: 0.8947 -- iter: 7/7\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.41712\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 674 | loss: 0.41712 - acc: 0.8767 -- iter: 7/7\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.37999\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 675 | loss: 0.37999 - acc: 0.8890 -- iter: 7/7\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.34665\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 676 | loss: 0.34665 - acc: 0.9001 -- iter: 7/7\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.37155\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 677 | loss: 0.37155 - acc: 0.9101 -- iter: 7/7\n",
      "--\n",
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.37155\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 678 | loss: 0.37155 - acc: 0.8905 -- iter: 7/7\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.33923\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 679 | loss: 0.33923 - acc: 0.9015 -- iter: 7/7\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.39528\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 680 | loss: 0.39528 - acc: 0.8827 -- iter: 7/7\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.36073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 681 | loss: 0.36073 - acc: 0.8945 -- iter: 7/7\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.49297\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 682 | loss: 0.49297 - acc: 0.8479 -- iter: 7/7\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.44883\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 683 | loss: 0.44883 - acc: 0.8631 -- iter: 7/7\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.40919\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 684 | loss: 0.40919 - acc: 0.8768 -- iter: 7/7\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.37361\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 685 | loss: 0.37361 - acc: 0.8891 -- iter: 7/7\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.49915\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 686 | loss: 0.49915 - acc: 0.8430 -- iter: 7/7\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.45476\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 687 | loss: 0.45476 - acc: 0.8587 -- iter: 7/7\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.41492\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 688 | loss: 0.41492 - acc: 0.8729 -- iter: 7/7\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.37914\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 689 | loss: 0.37914 - acc: 0.8856 -- iter: 7/7\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.34702\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 690 | loss: 0.34702 - acc: 0.8970 -- iter: 7/7\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.31817\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 691 | loss: 0.31817 - acc: 0.9073 -- iter: 7/7\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.29225\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 692 | loss: 0.29225 - acc: 0.9166 -- iter: 7/7\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.26897\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 693 | loss: 0.26897 - acc: 0.9249 -- iter: 7/7\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.24804\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 694 | loss: 0.24804 - acc: 0.9324 -- iter: 7/7\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.22922\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 695 | loss: 0.22922 - acc: 0.9392 -- iter: 7/7\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.21230\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 696 | loss: 0.21230 - acc: 0.9453 -- iter: 7/7\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.19707\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 697 | loss: 0.19707 - acc: 0.9557 -- iter: 7/7\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.17102\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 698 | loss: 0.17102 - acc: 0.9557 -- iter: 7/7\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.17102\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 699 | loss: 0.17102 - acc: 0.9601 -- iter: 7/7\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.15989\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 700 | loss: 0.15989 - acc: 0.9641 -- iter: 7/7\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.14986\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 701 | loss: 0.14986 - acc: 0.9677 -- iter: 7/7\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.14080\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 702 | loss: 0.14080 - acc: 0.9709 -- iter: 7/7\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.13262\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 703 | loss: 0.13262 - acc: 0.9738 -- iter: 7/7\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.12523\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 704 | loss: 0.12523 - acc: 0.9764 -- iter: 7/7\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.11855\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 705 | loss: 0.11855 - acc: 0.9788 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.11249\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 706 | loss: 0.11249 - acc: 0.9809 -- iter: 7/7\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.10700\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 707 | loss: 0.10700 - acc: 0.9828 -- iter: 7/7\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.10202\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 708 | loss: 0.10202 - acc: 0.9845 -- iter: 7/7\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.09750\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 709 | loss: 0.09750 - acc: 0.9861 -- iter: 7/7\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.08963\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 710 | loss: 0.08963 - acc: 0.9875 -- iter: 7/7\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.08620\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 711 | loss: 0.08620 - acc: 0.9887 -- iter: 7/7\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.08620\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 712 | loss: 0.08620 - acc: 0.9899 -- iter: 7/7\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.08307\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 713 | loss: 0.08307 - acc: 0.9909 -- iter: 7/7\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.08021\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 714 | loss: 0.08021 - acc: 0.9918 -- iter: 7/7\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.07758\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 715 | loss: 0.07758 - acc: 0.9926 -- iter: 7/7\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.07517\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 716 | loss: 0.07517 - acc: 0.9933 -- iter: 7/7\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.07294\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 717 | loss: 0.07294 - acc: 0.9940 -- iter: 7/7\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.07089\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 718 | loss: 0.07089 - acc: 0.9946 -- iter: 7/7\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.06900\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 719 | loss: 0.06900 - acc: 0.9951 -- iter: 7/7\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.06724\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 720 | loss: 0.06724 - acc: 0.9956 -- iter: 7/7\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.06561\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 721 | loss: 0.06561 - acc: 0.9961 -- iter: 7/7\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.22698\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 722 | loss: 0.22698 - acc: 0.9393 -- iter: 7/7\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.20934\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 723 | loss: 0.20934 - acc: 0.9454 -- iter: 7/7\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.19346\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 724 | loss: 0.19346 - acc: 0.9509 -- iter: 7/7\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.17917\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 725 | loss: 0.17917 - acc: 0.9558 -- iter: 7/7\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.16630\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 726 | loss: 0.16630 - acc: 0.9602 -- iter: 7/7\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.15471\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 727 | loss: 0.15471 - acc: 0.9642 -- iter: 7/7\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.14426\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 728 | loss: 0.14426 - acc: 0.9678 -- iter: 7/7\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.12634\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 729 | loss: 0.12634 - acc: 0.9710 -- iter: 7/7\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.12634\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 730 | loss: 0.12634 - acc: 0.9739 -- iter: 7/7\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.11867\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 731 | loss: 0.11867 - acc: 0.9765 -- iter: 7/7\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.11173\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 732 | loss: 0.11173 - acc: 0.9788 -- iter: 7/7\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.10546\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 733 | loss: 0.10546 - acc: 0.9810 -- iter: 7/7\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.09979\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 734 | loss: 0.09979 - acc: 0.9829 -- iter: 7/7\n",
      "--\n",
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.09465\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 735 | loss: 0.09465 - acc: 0.9846 -- iter: 7/7\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.08999\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 736 | loss: 0.08999 - acc: 0.9861 -- iter: 7/7\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.08576\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 737 | loss: 0.08576 - acc: 0.9875 -- iter: 7/7\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.08192\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 738 | loss: 0.08192 - acc: 0.9888 -- iter: 7/7\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.07843\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 739 | loss: 0.07843 - acc: 0.9899 -- iter: 7/7\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.07524\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 740 | loss: 0.07524 - acc: 0.9909 -- iter: 7/7\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.07234\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 741 | loss: 0.07234 - acc: 0.9918 -- iter: 7/7\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.06969\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 742 | loss: 0.06969 - acc: 0.9926 -- iter: 7/7\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.06727\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 743 | loss: 0.06727 - acc: 0.9934 -- iter: 7/7\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.06504\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 744 | loss: 0.06504 - acc: 0.9940 -- iter: 7/7\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.06301\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 745 | loss: 0.06301 - acc: 0.9946 -- iter: 7/7\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.14865\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 746 | loss: 0.14865 - acc: 0.9666 -- iter: 7/7\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.13820\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 747 | loss: 0.13820 - acc: 0.9699 -- iter: 7/7\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.12878\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 748 | loss: 0.12878 - acc: 0.9729 -- iter: 7/7\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.12029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 749 | loss: 0.12029 - acc: 0.9756 -- iter: 7/7\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.11262\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 750 | loss: 0.11262 - acc: 0.9781 -- iter: 7/7\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m0.10570\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 751 | loss: 0.10570 - acc: 0.9803 -- iter: 7/7\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m0.09944\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 752 | loss: 0.09944 - acc: 0.9822 -- iter: 7/7\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m0.09379\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 753 | loss: 0.09379 - acc: 0.9840 -- iter: 7/7\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m0.08868\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 754 | loss: 0.08868 - acc: 0.9856 -- iter: 7/7\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m0.08405\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 755 | loss: 0.08405 - acc: 0.9871 -- iter: 7/7\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m0.25142\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 756 | loss: 0.25142 - acc: 0.9312 -- iter: 7/7\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m0.23051\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 757 | loss: 0.23051 - acc: 0.9381 -- iter: 7/7\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m0.21171\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 758 | loss: 0.21171 - acc: 0.9443 -- iter: 7/7\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m0.19480\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 759 | loss: 0.19480 - acc: 0.9499 -- iter: 7/7\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m0.17959\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 760 | loss: 0.17959 - acc: 0.9549 -- iter: 7/7\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m0.15358\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 761 | loss: 0.15358 - acc: 0.9594 -- iter: 7/7\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m0.15358\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 762 | loss: 0.15358 - acc: 0.9634 -- iter: 7/7\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m0.30972\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 763 | loss: 0.30972 - acc: 0.9671 -- iter: 7/7\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m0.28305\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 764 | loss: 0.28305 - acc: 0.9132 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m0.28305\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 765 | loss: 0.28305 - acc: 0.9219 -- iter: 7/7\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m0.25908\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 766 | loss: 0.25908 - acc: 0.9297 -- iter: 7/7\n",
      "--\n",
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m0.23753\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 767 | loss: 0.23753 - acc: 0.9368 -- iter: 7/7\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m0.20074\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 768 | loss: 0.20074 - acc: 0.9431 -- iter: 7/7\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m0.20074\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 769 | loss: 0.20074 - acc: 0.9488 -- iter: 7/7\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m0.18507\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 770 | loss: 0.18507 - acc: 0.9539 -- iter: 7/7\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m0.15829\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 771 | loss: 0.15829 - acc: 0.9585 -- iter: 7/7\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m0.14686\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 772 | loss: 0.14686 - acc: 0.9627 -- iter: 7/7\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m0.13657\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 773 | loss: 0.13657 - acc: 0.9664 -- iter: 7/7\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m0.12730\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 774 | loss: 0.12730 - acc: 0.9698 -- iter: 7/7\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m0.11894\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 775 | loss: 0.11894 - acc: 0.9728 -- iter: 7/7\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m0.11140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 776 | loss: 0.11140 - acc: 0.9755 -- iter: 7/7\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m0.10460\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 777 | loss: 0.10460 - acc: 0.9779 -- iter: 7/7\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m0.10460\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 778 | loss: 0.10460 - acc: 0.9802 -- iter: 7/7\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m0.09845\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 779 | loss: 0.09845 - acc: 0.9821 -- iter: 7/7\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m0.09290\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 780 | loss: 0.09290 - acc: 0.9839 -- iter: 7/7\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m0.08787\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 781 | loss: 0.08787 - acc: 0.9855 -- iter: 7/7\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m0.08332\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 782 | loss: 0.08332 - acc: 0.9870 -- iter: 7/7\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m0.07920\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 783 | loss: 0.07920 - acc: 0.9883 -- iter: 7/7\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m0.07547\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 784 | loss: 0.07547 - acc: 0.9895 -- iter: 7/7\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m0.06899\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 785 | loss: 0.06899 - acc: 0.9905 -- iter: 7/7\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m0.06899\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 786 | loss: 0.06899 - acc: 0.9915 -- iter: 7/7\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m0.06618\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 787 | loss: 0.06618 - acc: 0.9923 -- iter: 7/7\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m0.06362\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 788 | loss: 0.06362 - acc: 0.9931 -- iter: 7/7\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m0.06129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 789 | loss: 0.06129 - acc: 0.9938 -- iter: 7/7\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m0.05721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 790 | loss: 0.05721 - acc: 0.9944 -- iter: 7/7\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m0.23212\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 791 | loss: 0.23212 - acc: 0.9950 -- iter: 7/7\n",
      "--\n",
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m0.21286\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 792 | loss: 0.21286 - acc: 0.9383 -- iter: 7/7\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m0.19554\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 793 | loss: 0.19554 - acc: 0.9445 -- iter: 7/7\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m0.17996\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 794 | loss: 0.17996 - acc: 0.9500 -- iter: 7/7\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m0.17996\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 795 | loss: 0.17996 - acc: 0.9550 -- iter: 7/7\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m0.16594\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 796 | loss: 0.16594 - acc: 0.9595 -- iter: 7/7\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m0.14197\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 797 | loss: 0.14197 - acc: 0.9636 -- iter: 7/7\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m0.14197\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 798 | loss: 0.14197 - acc: 0.9672 -- iter: 7/7\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.13175\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 799 | loss: 0.13175 - acc: 0.9705 -- iter: 7/7\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.12253\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 800 | loss: 0.12253 - acc: 0.9734 -- iter: 7/7\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m0.11423\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 801 | loss: 0.11423 - acc: 0.9761 -- iter: 7/7\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m0.09999\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 802 | loss: 0.09999 - acc: 0.9785 -- iter: 7/7\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m0.09389\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 803 | loss: 0.09389 - acc: 0.9806 -- iter: 7/7\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m0.09389\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 804 | loss: 0.09389 - acc: 0.9826 -- iter: 7/7\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m0.08838\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 805 | loss: 0.08838 - acc: 0.9843 -- iter: 7/7\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m0.08341\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 806 | loss: 0.08341 - acc: 0.9859 -- iter: 7/7\n",
      "--\n",
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m0.07890\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 807 | loss: 0.07890 - acc: 0.9873 -- iter: 7/7\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m0.07114\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 808 | loss: 0.07114 - acc: 0.9886 -- iter: 7/7\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m0.07114\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 809 | loss: 0.07114 - acc: 0.9897 -- iter: 7/7\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m0.06779\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 810 | loss: 0.06779 - acc: 0.9907 -- iter: 7/7\n",
      "--\n",
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m0.06475\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 811 | loss: 0.06475 - acc: 0.9917 -- iter: 7/7\n",
      "--\n",
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m0.06199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 812 | loss: 0.06199 - acc: 0.9925 -- iter: 7/7\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m0.05947\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 813 | loss: 0.05947 - acc: 0.9933 -- iter: 7/7\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m0.05718\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 814 | loss: 0.05718 - acc: 0.9939 -- iter: 7/7\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m0.05510\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 815 | loss: 0.05510 - acc: 0.9945 -- iter: 7/7\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m0.14518\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 816 | loss: 0.14518 - acc: 0.9665 -- iter: 7/7\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m0.13426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 817 | loss: 0.13426 - acc: 0.9699 -- iter: 7/7\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m0.11557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 818 | loss: 0.11557 - acc: 0.9729 -- iter: 7/7\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m0.11557\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 819 | loss: 0.11557 - acc: 0.9756 -- iter: 7/7\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m0.18027\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 820 | loss: 0.18027 - acc: 0.9495 -- iter: 7/7\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m0.18027\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 821 | loss: 0.18027 - acc: 0.9545 -- iter: 7/7\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m0.23426\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 822 | loss: 0.23426 - acc: 0.9305 -- iter: 7/7\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m0.23426\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 823 | loss: 0.23426 - acc: 0.9374 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m0.19670\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 824 | loss: 0.19670 - acc: 0.9437 -- iter: 7/7\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m0.18071\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 825 | loss: 0.18071 - acc: 0.9493 -- iter: 7/7\n",
      "--\n",
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m0.16632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 826 | loss: 0.16632 - acc: 0.9544 -- iter: 7/7\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m0.15338\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 827 | loss: 0.15338 - acc: 0.9590 -- iter: 7/7\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m0.14174\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 828 | loss: 0.14174 - acc: 0.9631 -- iter: 7/7\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m0.14174\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 829 | loss: 0.14174 - acc: 0.9668 -- iter: 7/7\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m0.31149\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 830 | loss: 0.31149 - acc: 0.9216 -- iter: 7/7\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m0.28408\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 831 | loss: 0.28408 - acc: 0.9216 -- iter: 7/7\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m0.25944\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 832 | loss: 0.25944 - acc: 0.9295 -- iter: 7/7\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m0.23730\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 833 | loss: 0.23730 - acc: 0.9365 -- iter: 7/7\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m0.21740\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 834 | loss: 0.21740 - acc: 0.9429 -- iter: 7/7\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m0.18342\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 835 | loss: 0.18342 - acc: 0.9486 -- iter: 7/7\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m0.18342\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 836 | loss: 0.18342 - acc: 0.9584 -- iter: 7/7\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m0.16895\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 837 | loss: 0.16895 - acc: 0.9584 -- iter: 7/7\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m0.15593\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 838 | loss: 0.15593 - acc: 0.9625 -- iter: 7/7\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m0.14421\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 839 | loss: 0.14421 - acc: 0.9663 -- iter: 7/7\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m0.13366\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 840 | loss: 0.13366 - acc: 0.9696 -- iter: 7/7\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m0.12416\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 841 | loss: 0.12416 - acc: 0.9727 -- iter: 7/7\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m0.20704\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 842 | loss: 0.20704 - acc: 0.9468 -- iter: 7/7\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m0.19021\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 843 | loss: 0.19021 - acc: 0.9522 -- iter: 7/7\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m0.17507\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 844 | loss: 0.17507 - acc: 0.9569 -- iter: 7/7\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m0.16145\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 845 | loss: 0.16145 - acc: 0.9612 -- iter: 7/7\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m0.13816\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 846 | loss: 0.13816 - acc: 0.9651 -- iter: 7/7\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m0.12823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 847 | loss: 0.12823 - acc: 0.9686 -- iter: 7/7\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m0.12823\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 848 | loss: 0.12823 - acc: 0.9717 -- iter: 7/7\n",
      "--\n",
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m0.11121\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 849 | loss: 0.11121 - acc: 0.9746 -- iter: 7/7\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m0.11121\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 850 | loss: 0.11121 - acc: 0.9771 -- iter: 7/7\n",
      "--\n",
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m0.10394\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 851 | loss: 0.10394 - acc: 0.9794 -- iter: 7/7\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m0.09738\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 852 | loss: 0.09738 - acc: 0.9815 -- iter: 7/7\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m0.09146\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 853 | loss: 0.09146 - acc: 0.9833 -- iter: 7/7\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m0.08611\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 854 | loss: 0.08611 - acc: 0.9850 -- iter: 7/7\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m0.08128\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 855 | loss: 0.08128 - acc: 0.9865 -- iter: 7/7\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m0.07691\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 856 | loss: 0.07691 - acc: 0.9878 -- iter: 7/7\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m0.07295\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 857 | loss: 0.07295 - acc: 0.9891 -- iter: 7/7\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m0.25387\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 858 | loss: 0.25387 - acc: 0.9330 -- iter: 7/7\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m0.23222\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 859 | loss: 0.23222 - acc: 0.9397 -- iter: 7/7\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.21276\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 860 | loss: 0.21276 - acc: 0.9457 -- iter: 7/7\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.19526\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 861 | loss: 0.19526 - acc: 0.9512 -- iter: 7/7\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.17952\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 862 | loss: 0.17952 - acc: 0.9560 -- iter: 7/7\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.16536\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 863 | loss: 0.16536 - acc: 0.9604 -- iter: 7/7\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m0.14115\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 864 | loss: 0.14115 - acc: 0.9644 -- iter: 7/7\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m0.14115\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 865 | loss: 0.14115 - acc: 0.9426 -- iter: 7/7\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m0.22393\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 866 | loss: 0.22393 - acc: 0.9426 -- iter: 7/7\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.18863\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 867 | loss: 0.18863 - acc: 0.9483 -- iter: 7/7\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.18863\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 868 | loss: 0.18863 - acc: 0.9535 -- iter: 7/7\n",
      "--\n",
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.17360\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 869 | loss: 0.17360 - acc: 0.9338 -- iter: 7/7\n",
      "--\n",
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m0.25495\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 870 | loss: 0.25495 - acc: 0.9338 -- iter: 7/7\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m0.23332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 871 | loss: 0.23332 - acc: 0.9404 -- iter: 7/7\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m0.39403\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 872 | loss: 0.39403 - acc: 0.8892 -- iter: 7/7\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m0.50064\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 873 | loss: 0.50064 - acc: 0.9003 -- iter: 7/7\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m0.45469\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 874 | loss: 0.45469 - acc: 0.8531 -- iter: 7/7\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m0.41342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 875 | loss: 0.41342 - acc: 0.8678 -- iter: 7/7\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m0.41342\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 876 | loss: 0.41342 - acc: 0.8810 -- iter: 7/7\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m0.37636\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 877 | loss: 0.37636 - acc: 0.8929 -- iter: 7/7\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m0.31316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 878 | loss: 0.31316 - acc: 0.9036 -- iter: 7/7\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m0.31316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 879 | loss: 0.31316 - acc: 0.9133 -- iter: 7/7\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m0.28629\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 880 | loss: 0.28629 - acc: 0.9219 -- iter: 7/7\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m0.26214\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 881 | loss: 0.26214 - acc: 0.9297 -- iter: 7/7\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m0.32460\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 882 | loss: 0.32460 - acc: 0.9082 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m0.29671\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 883 | loss: 0.29671 - acc: 0.9174 -- iter: 7/7\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m0.24913\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 884 | loss: 0.24913 - acc: 0.9256 -- iter: 7/7\n",
      "--\n",
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m0.24913\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 885 | loss: 0.24913 - acc: 0.9331 -- iter: 7/7\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m0.39629\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 886 | loss: 0.39629 - acc: 0.8826 -- iter: 7/7\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m0.36140\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 887 | loss: 0.36140 - acc: 0.8944 -- iter: 7/7\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m0.33007\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 888 | loss: 0.33007 - acc: 0.9049 -- iter: 7/7\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m0.30192\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 889 | loss: 0.30192 - acc: 0.9144 -- iter: 7/7\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m0.27663\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 890 | loss: 0.27663 - acc: 0.9230 -- iter: 7/7\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m0.25391\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 891 | loss: 0.25391 - acc: 0.9307 -- iter: 7/7\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m0.39461\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 892 | loss: 0.39461 - acc: 0.8805 -- iter: 7/7\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m0.36019\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 893 | loss: 0.36019 - acc: 0.8924 -- iter: 7/7\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m0.32928\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 894 | loss: 0.32928 - acc: 0.9032 -- iter: 7/7\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m0.30151\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 895 | loss: 0.30151 - acc: 0.9129 -- iter: 7/7\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m0.43565\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 896 | loss: 0.43565 - acc: 0.8644 -- iter: 7/7\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m0.39738\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 897 | loss: 0.39738 - acc: 0.8780 -- iter: 7/7\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m0.36301\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 898 | loss: 0.36301 - acc: 0.8902 -- iter: 7/7\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m0.33214\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 899 | loss: 0.33214 - acc: 0.9012 -- iter: 7/7\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m0.30441\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 900 | loss: 0.30441 - acc: 0.9111 -- iter: 7/7\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m0.27950\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 901 | loss: 0.27950 - acc: 0.9200 -- iter: 7/7\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m0.25712\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 902 | loss: 0.25712 - acc: 0.9280 -- iter: 7/7\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m0.23699\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 903 | loss: 0.23699 - acc: 0.9352 -- iter: 7/7\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m0.21890\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 904 | loss: 0.21890 - acc: 0.9416 -- iter: 7/7\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m0.20263\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 905 | loss: 0.20263 - acc: 0.9475 -- iter: 7/7\n",
      "--\n",
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m0.17480\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 906 | loss: 0.17480 - acc: 0.9527 -- iter: 7/7\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m0.17480\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 907 | loss: 0.17480 - acc: 0.9575 -- iter: 7/7\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m0.16293\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 908 | loss: 0.16293 - acc: 0.9617 -- iter: 7/7\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m0.15223\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 909 | loss: 0.15223 - acc: 0.9655 -- iter: 7/7\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m0.14258\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 910 | loss: 0.14258 - acc: 0.9690 -- iter: 7/7\n",
      "--\n",
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m0.13388\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 911 | loss: 0.13388 - acc: 0.9721 -- iter: 7/7\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m0.12602\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 912 | loss: 0.12602 - acc: 0.9749 -- iter: 7/7\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.11892\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 913 | loss: 0.11892 - acc: 0.9774 -- iter: 7/7\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.11250\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 914 | loss: 0.11250 - acc: 0.9797 -- iter: 7/7\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.10668\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 915 | loss: 0.10668 - acc: 0.9817 -- iter: 7/7\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m0.10142\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 916 | loss: 0.10142 - acc: 0.9835 -- iter: 7/7\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m0.09664\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 917 | loss: 0.09664 - acc: 0.9852 -- iter: 7/7\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m0.09231\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 918 | loss: 0.09231 - acc: 0.9867 -- iter: 7/7\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m0.08837\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 919 | loss: 0.08837 - acc: 0.9880 -- iter: 7/7\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m0.08478\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 920 | loss: 0.08478 - acc: 0.9892 -- iter: 7/7\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m0.07852\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 921 | loss: 0.07852 - acc: 0.9903 -- iter: 7/7\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m0.07852\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 922 | loss: 0.07852 - acc: 0.9912 -- iter: 7/7\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m0.07579\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 923 | loss: 0.07579 - acc: 0.9921 -- iter: 7/7\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m0.23786\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 924 | loss: 0.23786 - acc: 0.9358 -- iter: 7/7\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m0.21916\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 925 | loss: 0.21916 - acc: 0.9422 -- iter: 7/7\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m0.28464\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 926 | loss: 0.28464 - acc: 0.9194 -- iter: 7/7\n",
      "--\n",
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m0.26131\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 927 | loss: 0.26131 - acc: 0.9275 -- iter: 7/7\n",
      "--\n",
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m0.24033\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 928 | loss: 0.24033 - acc: 0.9347 -- iter: 7/7\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m0.22146\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 929 | loss: 0.22146 - acc: 0.9412 -- iter: 7/7\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m0.20449\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 930 | loss: 0.20449 - acc: 0.9471 -- iter: 7/7\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m0.18922\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 931 | loss: 0.18922 - acc: 0.9524 -- iter: 7/7\n",
      "--\n",
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m0.17548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 932 | loss: 0.17548 - acc: 0.9572 -- iter: 7/7\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m0.15195\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 933 | loss: 0.15195 - acc: 0.9614 -- iter: 7/7\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m0.15195\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 934 | loss: 0.15195 - acc: 0.9653 -- iter: 7/7\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m0.14190\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 935 | loss: 0.14190 - acc: 0.9688 -- iter: 7/7\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m0.21194\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 936 | loss: 0.21194 - acc: 0.9433 -- iter: 7/7\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.19588\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 937 | loss: 0.19588 - acc: 0.9490 -- iter: 7/7\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m0.34604\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 938 | loss: 0.34604 - acc: 0.8969 -- iter: 7/7\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m0.31662\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 939 | loss: 0.31662 - acc: 0.9073 -- iter: 7/7\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m0.45046\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 940 | loss: 0.45046 - acc: 0.8594 -- iter: 7/7\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m0.41073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 941 | loss: 0.41073 - acc: 0.8734 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m0.37506\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 942 | loss: 0.37506 - acc: 0.8861 -- iter: 7/7\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m0.34302\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 943 | loss: 0.34302 - acc: 0.8975 -- iter: 7/7\n",
      "--\n",
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m0.31423\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 944 | loss: 0.31423 - acc: 0.9077 -- iter: 7/7\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m0.28837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 945 | loss: 0.28837 - acc: 0.9170 -- iter: 7/7\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m0.26513\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 946 | loss: 0.26513 - acc: 0.9253 -- iter: 7/7\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m0.24423\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 947 | loss: 0.24423 - acc: 0.9327 -- iter: 7/7\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m0.22545\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 948 | loss: 0.22545 - acc: 0.9395 -- iter: 7/7\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m0.20855\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 949 | loss: 0.20855 - acc: 0.9455 -- iter: 7/7\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m0.32435\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 950 | loss: 0.32435 - acc: 0.8938 -- iter: 7/7\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m0.32435\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 951 | loss: 0.32435 - acc: 0.9044 -- iter: 7/7\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m0.29766\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 952 | loss: 0.29766 - acc: 0.9140 -- iter: 7/7\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m0.27368\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 953 | loss: 0.27368 - acc: 0.9226 -- iter: 7/7\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m0.25213\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 954 | loss: 0.25213 - acc: 0.9303 -- iter: 7/7\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m0.23275\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 955 | loss: 0.23275 - acc: 0.9373 -- iter: 7/7\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m0.36868\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 956 | loss: 0.36868 - acc: 0.8864 -- iter: 7/7\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m0.33771\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 957 | loss: 0.33771 - acc: 0.8978 -- iter: 7/7\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m0.30990\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 958 | loss: 0.30990 - acc: 0.9080 -- iter: 7/7\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m0.28491\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 959 | loss: 0.28491 - acc: 0.9172 -- iter: 7/7\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.26244\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 960 | loss: 0.26244 - acc: 0.9255 -- iter: 7/7\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m0.22408\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 961 | loss: 0.22408 - acc: 0.9329 -- iter: 7/7\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m0.22408\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 962 | loss: 0.22408 - acc: 0.9457 -- iter: 7/7\n",
      "--\n",
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m0.19303\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 963 | loss: 0.19303 - acc: 0.9457 -- iter: 7/7\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m0.17978\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 964 | loss: 0.17978 - acc: 0.9511 -- iter: 7/7\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m0.17978\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 965 | loss: 0.17978 - acc: 0.9560 -- iter: 7/7\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m0.16785\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 966 | loss: 0.16785 - acc: 0.9604 -- iter: 7/7\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m0.15709\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 967 | loss: 0.15709 - acc: 0.9644 -- iter: 7/7\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m0.14739\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 968 | loss: 0.14739 - acc: 0.9679 -- iter: 7/7\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m0.13863\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 969 | loss: 0.13863 - acc: 0.9711 -- iter: 7/7\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m0.12356\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 970 | loss: 0.12356 - acc: 0.9740 -- iter: 7/7\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m0.12356\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 971 | loss: 0.12356 - acc: 0.9766 -- iter: 7/7\n",
      "--\n",
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m0.11122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 972 | loss: 0.11122 - acc: 0.9790 -- iter: 7/7\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m0.11122\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 973 | loss: 0.11122 - acc: 0.9811 -- iter: 7/7\n",
      "--\n",
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m0.10590\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 974 | loss: 0.10590 - acc: 0.9830 -- iter: 7/7\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m0.10108\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 975 | loss: 0.10108 - acc: 0.9847 -- iter: 7/7\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m0.17386\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 976 | loss: 0.17386 - acc: 0.9576 -- iter: 7/7\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m0.16218\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 977 | loss: 0.16218 - acc: 0.9619 -- iter: 7/7\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m0.15165\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 978 | loss: 0.15165 - acc: 0.9657 -- iter: 7/7\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m0.14215\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 979 | loss: 0.14215 - acc: 0.9691 -- iter: 7/7\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m0.13357\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 980 | loss: 0.13357 - acc: 0.9722 -- iter: 7/7\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m0.12583\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 981 | loss: 0.12583 - acc: 0.9750 -- iter: 7/7\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m0.11882\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 982 | loss: 0.11882 - acc: 0.9775 -- iter: 7/7\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m0.11248\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 983 | loss: 0.11248 - acc: 0.9797 -- iter: 7/7\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m0.10674\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 984 | loss: 0.10674 - acc: 0.9818 -- iter: 7/7\n",
      "--\n",
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m0.10154\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 985 | loss: 0.10154 - acc: 0.9836 -- iter: 7/7\n",
      "--\n",
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m0.09682\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 986 | loss: 0.09682 - acc: 0.9852 -- iter: 7/7\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m0.09253\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 987 | loss: 0.09253 - acc: 0.9867 -- iter: 7/7\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m0.08863\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 988 | loss: 0.08863 - acc: 0.9880 -- iter: 7/7\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m0.08507\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 989 | loss: 0.08507 - acc: 0.9892 -- iter: 7/7\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m0.22065\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 990 | loss: 0.22065 - acc: 0.9332 -- iter: 7/7\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m0.22065\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 991 | loss: 0.22065 - acc: 0.9398 -- iter: 7/7\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m0.20387\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 992 | loss: 0.20387 - acc: 0.9513 -- iter: 7/7\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m0.18877\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 993 | loss: 0.18877 - acc: 0.9513 -- iter: 7/7\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m0.17518\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 994 | loss: 0.17518 - acc: 0.9561 -- iter: 7/7\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m0.16293\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 995 | loss: 0.16293 - acc: 0.9605 -- iter: 7/7\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m0.15190\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 996 | loss: 0.15190 - acc: 0.9645 -- iter: 7/7\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m0.14195\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 997 | loss: 0.14195 - acc: 0.9680 -- iter: 7/7\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m0.13298\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 998 | loss: 0.13298 - acc: 0.9712 -- iter: 7/7\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m0.12488\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 999 | loss: 0.12488 - acc: 0.9741 -- iter: 7/7\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.11756\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1000 | loss: 0.11756 - acc: 0.9767 -- iter: 7/7\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/home/helmi/Jupyter/Chatbot1/model_entities.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_entities_logs', tensorboard_verbose=3)\n",
    "# Start training (apply gradient descent algorithm)\n",
    "model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "model.save('model_entities.tflearn')\n",
    "# save all of our data structures\n",
    "import pickle\n",
    "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"training_data_entities\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
